# LAMBDA

Data & Codes for:<br><br>
**Evolution of Virulence in Emerging Epidemics: From Theory to Experimental Evolution and Back**<br>
Wakinyan Benhamou, François Blanquart, Marc Choisy, Thomas W. Berngruber, Rémi Choquet and Sylvain Gandon

## Data (source and short descriptions)

This is previous experimental time series from [Berngruber *et al.* (2013)](https://doi.org/10.1371/journal.ppat.1003209) or simulated data from this study. All data used in the scripts are in the 'Data' folder and, within, simulated datasets are in the 'Simulated_data' subfolder.

The evolution experiment designed in [Berngruber *et al.* (2013)](https://doi.org/10.1371/journal.ppat.1003209) monitored the competition between two strains of phage $\lambda$ with distinct life-history strategies in continuous cultures of *Escherichia coli*. The first strain is the wildtype which is known to have a relatively large lysogenization rate and low reactivation rate. The second strain is the $\lambda$ cI857 variant, which is known to be more virulent and transmitted mostly horizontally through lytic cycles. There are 8 chemostats: 4 replicates x 2 treatments (epidemic, with an initial prevalence around 1% *vs.* endemic, with an initial prevalence around 99%). Viruses are first introduced as prophages with initial ratio 1:1.

### data_FACS.csv

&#11169;&emsp; Experimental times series of the (logit-)prevalence and viral strain (logit-)frequencies among infected cells.

### data_qPCR.csv

&#11169;&emsp; Experimental times series of the viral strain (logit-)frequencies in the culture medium.

### Experimental_data_mean_and_figures.RData

&#11169;&emsp; This R Data file (generated by **Experimental_data_mean_and_figures.R**, in the root directory of this repositery) stores in a single file:
- The R dataframes `data_FACS` and `data_qPCR` corresponding to **data_FACS.csv** and **data_qPCR.csv**, respectively;
- The R dataframes `data_FACS_mean` and `data_qPCR_mean` containing mean values accross chemostats for each treatment;
- Plots of experimental times series (logit-prevalence, logit-frequency infected by virulent phage and logit-frequency free virulent phage over time).

### Simulated_data/

Simulated datasets, as generated by **Simulate_Data.R** (root directory of this repositery), for 8 chemostats: 4 replicates x 2 treatments (epidemic *vs.* endemic). The file **parms_simul.csv** stores the parameter values used for the simulations. Files whose name contains '*Simul_data_FACS*' simulate times series of the (logit-)prevalence and viral strain (logit-)frequencies among infected cells; files whose name contains '*Simul_data_qPCR*' simulate times series of the viral strain (logit-)frequencies in the free virus stage. Eventually, the meaning of the code number (between 1 and 4) just before the extension '*.csv*' is as follows:
|                                        | Samplings every 0.1 h | Samplings every 1 h |
| :---                                   |         :---:         |         :---:       |
| Almost no measurement errors (SD=0.01) |           1           |          3          |
| Greater measurement errors (SD=0.5)    |           2           |          4          |

The R data file **simul_data.RData** (also generates by **Simulate_Data.R**) contains all the previous simulated datasets:

`Simul_data_FACS.1`, `Simul_data_FACS.2`, `Simul_data_FACS.3`, `Simul_data_FACS.4`, `Simul_data_qPCR.1`, `Simul_data_qPCR.2`, `Simul_data_qPCR.3` and `Simul_data_qPCR.4`,

along with the original simulation (`simul`) and the parameter values (`parms`).

## R codes

Scripts in the root directory:

- **Experimental_data_mean_and_figures.R** (generates **Experimental_data_mean_and_figures.RData**, *cf.* see above)
- **Phage_Lambda_functions_v11.R** (script with all the main custom functions used in this study)
- **Simulate_Data.R** (simulates all the datasets present in 'Data/Simulated_data', *cf.* see above)
- **Theoretical_figures.R** (plots theoretical figures Fig. 2, S1, S3, S4 and S13)

We developed an inference approach to estimate the parameters of the model. We implemented a two-step MLE (Maximum Likelihood Estimation) procedure: (i) we first obtained point estimates of the rates of prophage reactivation $\alpha_w$ and $\alpha_m$ of both viral strains, (ii) then we fixed $\alpha_w$ and $\alpha_m$ to their point estimates and we ran non-linear optimizations to infer the remaining parameters of the model (except the burst size $B$ which had to be fixed because of an identifiability issue).

### Inference_rates_prophage_reactivation/

Statistical inference of the rates of prophage reactivation $\alpha_w$ and $\alpha_m$.

Scripts:
- **Inference_rates_of_prophage_reactivation_frequentist.Rmd** (frequentist inference of $\alpha_w$ and $\alpha_m$ (point estimates) from both simulated and experimental data; plots Fig. S5)
- **Inference_rates_of_prophage_reactivation_Bayesian.Rmd** (Bayesian inference of $\alpha_w$ and $\alpha_m$ from experimental data; plots Fig. S14)

RData:
- **RJAGS_MCMC.RData** (Monte Carlo Markov Chains simulations from **Inference_rates_of_prophage_reactivation_Bayesian.Rmd**)

### Non_linear_optimizations/

Statistical inference of the remaining parameters of the model $\theta=(\phi_w, \phi_m, a, b, r, \tau, P_0^{epidemic}, P_0^{endemic}, p_0)$. We fixed the burst size $B$ to 80 phages/cell because we demonstrated that it was not separately identifiable from the probability of fusion $b$ - only the product $b\times B$ is - (see subsection **LogLikelihood_landscape_b_B/**).

#### From_simulated_data/

We carry out an analysis based on simulated data (*cf.* see above subsection **Simulated_data/**) in order to validate our ability to infer parameters from experimental data.

Scripts:
- **estim_simulated_data_1_v11.R** (runs non-linear optimizations with simulated datasets 1)
- **estim_simulated_data_2_v11.R** (runs non-linear optimizations with simulated datasets 2)
- **estim_simulated_data_3_v11.R** (runs non-linear optimizations with simulated datasets 3)
- **estim_simulated_data_4_v11.R** (runs non-linear optimizations with simulated datasets 4)
- **Phage_lambda_simulated_data_nmk_v11.Rmd** (processes the results of the previous scripts, plots Fig. S7)

##### LogLikelihood_landscape_b_B/

To show that parameters $B$ and $b$ were not separately identifiable, we compute the log-likelihood landscape of $b$ *vs.* $B$.

Scripts:
- **LogLikelihood_landscape_b_B.R** (computes the log-likelihood for numerous combinations of $\\{b,B\\}$ from the simulated dataset closest to the original simulation (1))
- **LogLikelihood_landscape_b_B_figure.R** (plots Fig. S6)

#### From_experimental_data/

Scripts:
- **estim_experimental_data_v11.R** (runs non-linear optimizations with experimental data)
- **estim_experimental_data_v11_varB.R** (runs non-linear optimizations with experimental data for different fixed values of $B$ (sensitivity analysis))
- **estim_experimental_data_v11_vara.R** (runs non-linear optimizations with experimental data for different fixed values of $a$ (sensitivity analysis))
- **estim_experimental_data_v11_varr.R** (runs non-linear optimizations with experimental data for different fixed values of $r$ (sensitivity analysis))
- **estim_experimental_data_bootstrap_v11.R** (runs non-linear optimizations for 10,000 bootstraped datasets to compute joint distributions of estimated parameters)
- **Phage_lambda_experimental_data_nmk_v11.Rmd** (processes the results of all the previous scripts; fits ARMA models to residuals and generates bootstraped datasets; and plots Fig. 4, S8, S9, S10, S11, S12)

## Outputs (csv files)

The 'Outputs_csv' folder hosts a part of what was generated by the scripts (csv files). In particular, many of them were generated after very long running times - e.g. non-linear optimizations.

### Using simulated data

We first used simulated data. We ran non-linear optimizations from a set of 2,000 initial conditions; we reiterate this procedure five times so that we get five point estimates for each parameters (one for each set of 2,000 initial conditions).

- **Estim_nmk_parallel_simulated_data_sd_noise_001_timestep_01_n5x2000_seed123_v11.csv** (using simulated data 1)
- **Estim_nmk_parallel_simulated_data_sd_noise_05_timestep_01_n5x2000_seed123_v11.csv** (using simulated data 2)
- **Estim_nmk_parallel_simulated_data_sd_noise_001_timestep_1_n5x2000_seed123_v11.csv** (using simulated data 3)
- **Estim_nmk_parallel_simulated_data_sd_noise_05_timestep_1_n5x2000_seed123_v11.csv** (using simulated data 4)

### Using experimental data

We then used experimental data, starting from one set of 2,000 initial conditions.

- **Estim_nmk_parallel_experimental_data_nstarts2000_B80_v11.csv**
- **Best_parms_non_linear_optim_experimental_data.csv** (best fit from the previous file)

### Sensitivity analyses

To test the impact of the fixed value used for the burst size $B$, we studied how perturbations of the original value (80 phages/cell) affected the estimation of the other parameter values (new point estimates from non-linear optimizations).

- **Estim_nmk_parallel_experimental_data_nstarts2000_B60_v11.csv** (perturbation $B$ -25%)
- **Estim_nmk_parallel_experimental_data_nstarts2000_B72_v11.csv** (perturbation $B$ -10%)
- **Estim_nmk_parallel_experimental_data_nstarts2000_B88_v11.csv** (perturbation $B$ +10%)
- **Estim_nmk_parallel_experimental_data_nstarts2000_B100_v11.csv** (perturbation $B$ +25%)
- **Estim_nmk_parallel_experimental_data_nstarts2000_B120_v11.csv** (perturbation $B$ +50%)

We did the same with parameter $a$, which was first poorly estimated.

- **Estim_nmk_parallel_experimental_data_nstarts2000_a1e-09_v11.csv** ($a=10^{-9}$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_a1e-08_v11.csv** ($a=10^{-8}$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_a1e-07_v11.csv** ($a=10^{-7}$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_a1e-06_v11.csv** ($a=10^{-6}$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_a1e-04_v11.csv** ($a=10^{-4}$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_a0.01_v11.csv** ($a=10^{-2}$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_a1_v11.csv** ($a=1$)

Likewise, we did the same with parameter $r$, which was also first poorly estimated.

- **Estim_nmk_parallel_experimental_data_nstarts2000_r1_v11.csv** ($r=1$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_r2_v11.csv** ($r=2$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_r3_v11.csv** ($r=3$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_r4_v11.csv** ($r=4$)
- **Estim_nmk_parallel_experimental_data_nstarts2000_r5_v11.csv** ($r=5$)

### Sieve bootstrap

- **Bootstrapped_data.csv** (10,000 bootstraped datasets)
- **Estim_nmk_parallel_experimental_data_bootstrap_B80_v11.csv** (joint distributions of estimated parameters)
- **Simulations_bootstrap.csv** (fitted simulations)

### Log-likelihood landscape of $b$ *vs.* $B$

- **Lambda_landscape_b_B_v11_n40401_maxfeval8000.csv**
